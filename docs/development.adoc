= Development Guide
:toc: macro
:toc-title:
:toclevels: 1

toc::[]

== Setting up

 . link:https://help.github.com/en/articles/fork-a-repo[Fork] the link:https://github.com/openshift/odo[`odo`] repository.

 . Clone your fork:
+
NOTE: The following commands assume that you have the `$GOPATH` environment variable properly set. We highly recommend you place `odo` code into the $GOPATH.
+

----
$ git clone https://github.com/<YOUR_GITHUB_USERNAME>/odo.git $GOPATH/src/github.com/openshift/odo
$ cd $GOPATH/src/github.com/openshift/odo
$ git remote add upstream 'https://github.com/openshift/odo'
----
+
When cloning `odo`, the Windows terminal such as PowerShell or CMD may throw a *Filename too long* error. To avoid such an error, set your Git configuration as follows:
+
----
$ git config --system core.longpaths true
----

 . Install tools used by the build and test system:
+
----
$ make goget-tools
----

== Submitting a pull request(PR)

 . Create a branch, refer to the guidelines below in the sections below, and create a PR with your changes. If your PR is still in-progress, indicate this with a label or add WIP in your PR title.
+
A PR must include:

 * Descriptive context that outlines what has been changed and why
 * A link to the active or open issue it fixes (if applicable)

== Useful make targets

bin:: (default) `go build` the executable in cmd/odo
install:: build and install `odo` in your GOPATH
validate:: run gofmt, go vet and other validity checks
goget-tools:: download tools used to build & test
test:: run all unit tests - same as `go test pkg/...`
test-integration:: run all integration tests
test-coverage:: generate test coverage report

Read the Makefile itself for more information.


== Reviewing a PR

=== PR review process

. Once you submit a PR, the @openshift-ci-robot automatically requests two reviews from reviewers and suggests an approver based on `OWNERS` files.
. After a reviewer is satisfied with the changes he adds `/lgtm` (looks good to me) as a comment to the PR. This applies the *lgtm* label.
. The approver then reviews the PR and if satisfied, adds
`/approve` as a comment to the PR. This applies the *approve* label.
* After the PR has *lgtm* and *approve* labels and the required tests pass, the bot automatically merges the PR.
+
NOTE: If you are a maintainer and have write access to the `odo` repository, modify your git configuration so that you do not accidentally push to upstream:
+
----
$ git remote set-url --push upstream no_push
----

=== What to look out for when reviewing a pull request:

* Have tests been added?
* Does the feature or fix work locally?
* Is the code understandable, have comments been added to the code?
* A PR should pass all the pre-submit tests, all request changes must be resolved, and needs at least two approving reviews. If you apply the `/lgtm` label before it meets this criteria, put it on hold with the `/hold` label immediately. You can use `/lgtm cancel` to cancel your `/lgtm` and use `/hold cancel` once you are ready to approve it. This especially applies to draft PRs.
* Approvers can use `/approve` and `/approve cancel` to approve or hold their approval respectively.

=== About Prow
`odo` uses the link:https://github.com/kubernetes/test-infra/tree/master/prow[Prow] infrastucture for CI testing.
* It uses link:https://github.com/kubernetes/community/blob/master/contributors/guide/owners.md[OWNERS] files to determine who can approve and lgtm a PR.
* Prow has two levels of OWNERS, *Approvers* and *Reviewers*
** *Approvers* look for holistic acceptance criteria, including
dependencies with other features, forward and backward compatibility, API and flag definitions, etc. In essence, the high levels of design
** *Reviewers* look for general code quality, correctness, sane software engineering, style, etc. In essence, the quality of the actual code itself.

* Avoid merging the PR manually, unless it is an emergency and  you have the required permissions). Prowâ€™s tide component automatically merges the PR once all the conditions are met.
It also ensures that post-submit tests (tests that run before merge) validate the PR.
* Use the link:https://deck-ci.svc.ci.openshift.org/command-help[command-help] to see the list of possible bot commands.

== Test Driven Development

We follow the Test Driven Development(TDD) workflow in our development process. You can read more about it link:tdd-workflow.adoc[here].

=== Unit tests

Unit tests for `odo` functions are written using package
https://godoc.org/k8s.io/client-go/kubernetes/fake[fake]. This allows us to create a fake client, and then mock the API calls defined under link:https://github.com/openshift/client-go[OpenShift client-go] and link:https://godoc.org/k8s.io/client-go[k8s client-go].

The tests are written in golang using the https://golang.org/pkg/testing/[pkg/testing] package.

==== Writing unit tests

. Identify the APIs used by the function to be tested.
. Initialize the fake client along with the relevant client sets.
The following example explains the initialization of fake clients and the creation of fake objects.
+
The function `GetImageStreams` in https://github.com/openshift/odo/blob/master/pkg/occlient/occlient.go[`pkg/occlient.go`] fetches imagestream objects through the API:
+
[source,go]
----
func (c *Client) GetImageStreams(namespace string) ([]imagev1.ImageStream, error) {
        imageStreamList, err := c.imageClient.ImageStreams(namespace).List(metav1.ListOptions{})
        if err != nil {
                return nil, errors.Wrap(err, "unable to list imagestreams")
        }
        return imageStreamList.Items, nil
}
----

 .. For writing the tests, start by initializing the fake client using the function `FakeNew()` which initializes the image clientset harnessed by `GetImageStreams` function:
+
[source,go]
----
client, fkclientset := FakeNew()
----
.. In the `GetImageStreams` functions, the list of imagestreams is fetched through the API. While using fake client, this list can be emulated using a https://github.com/kubernetes/client-go/blob/master/testing/fake.go[`PrependReactor`] interface:
+
[source,go]
----
 fkclientset.ImageClientset.PrependReactor("list", "imagestreams", func(action ktesting.Action) (bool, runtime.Object, error) {
         return true, fakeImageStreams(tt.args.name, tt.args.namespace), nil
     })
----
+
The `PrependReactor` expects `resource` and `verb` to be passed in as arguments. Get this information by looking at the link:https://github.com/openshift/client-go/blob/master/image/clientset/versioned/typed/image/v1/fake/fake_imagestream.go[`List` function for fake imagestream]:
+
[source,go]
----
func (c *FakeImageStreams) List(opts v1.ListOptions) (result *image_v1.ImageStreamList, err error) {
        obj, err := c.Fake.Invokes(testing.NewListAction(imagestreamsResource, imagestreamsKind, c.ns, opts), &image_v1.ImageStreamList{})
    ...
}
 func NewListAction(resource schema.GroupVersionResource, kind schema.GroupVersionKind, namespace string, opts interface{}) ListActionImpl {
        action := ListActionImpl{}
        action.Verb = "list"
        action.Resource = resource
        action.Kind = kind
        action.Namespace = namespace
        labelSelector, fieldSelector, _ := ExtractFromListOptions(opts)
        action.ListRestrictions = ListRestrictions{labelSelector, fieldSelector}
         return action
}
----
+
The `List` function internally calls `NewListAction` defined in link:https://github.com/kubernetes/client-go/blob/master/testing/actions.go[`k8s.io/client-go/testing/actions.go`].
From these functions, we see that the `resource` and `verb` to be passed into the `PrependReactor` interface are `imagestreams` and `list` respectively.
+
You can see the entire test function `TestGetImageStream` in link:https://github.com/openshift/odo/blob/master/pkg/occlient/occlient_test.go[`pkg/occlient/occlient_test.go`].
+
NOTE: You can use environment variable `CUSTOM_HOMEDIR` to specify a custom home directory. It can be used in environments where a user and home directory are not resolvable.

. In the case where functions fetch or create new objects through the APIs, add a https://godoc.org/k8s.io/client-go/testing#Fake.AddReactor[reactor] interface returning fake objects.
. Verify the objects returned.

=== Integration tests

Integration tests are used within `odo`. All tests can be found in the `tests/` directory and can be called using functions within `makefile`. Also test directory comprises `e2e` scenario and a clean `test template` for reference.

.Prerequisites:

* A `minishift` or OpenShift environment with Service Catalog enabled:
+
----
$ MINISHIFT_ENABLE_EXPERIMENTAL=y minishift start --extra-clusterup-flags "--enable=*,service-catalog,automation-service-broker,template-service-broker"
----

* `odo` and `oc` binaries in `$PATH`.

.How to write:

Refer to the odo clean test link:https://github.com/openshift/odo/blob/master/tests/template/template_cleantest_test.go[`template`].

.Procedure:

Integration tests can be run in the following two ways:

* To run the tests in parallel (default: 2 ginkgo test node), on a test cluster:
+
Run component command integration tests
+
----
$ make test-cmp-e2e
----
+

Run application command integration tests
+
----
$ make test-cmd-app
----
+

Run storage command integration tests
+
----
$ make test-cmd-storage
----
+

Run watch command integration tests
+
----
$ make test-watch-e2e
----
+

Run config/preference command integration tests
+
----
$ make test-odo-config
----
+

Run generic integration tests
+
----
$ make test-generic
----
+

Run json output integration tests
+
----
$ make test-json-format-output
----
+

Run service command integration tests
+
----
$ make test-service-e2e
----
+

Run link/unlink command integration tests
+
----
$ make test-link-e2e
----
+

Run java source integration tests
+
----
$ make test-java-e2e
----
+

Run source integration tests
+
----
$ make test-source-e2e
----
+

* To run the tests sequentially or on single ginkgo test node use enviornment variable `TEST_EXEC_NODES`:
+
Run component command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-cmp-e2e
----
+

Run application command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-cmd-app
----
+

Run storage command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-cmd-storage
----
+

Run watch command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-watch-e2e
----
+

Run config/preference command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-odo-config
----
+

Run generic integration tests
+
----
$ TEST_EXEC_NODES=1 make test-generic
----
+

Run json output integration tests
+
----
$ TEST_EXEC_NODES=1 make test-json-format-output
----
+

Run service command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-service-e2e
----
+

Run link/unlink command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-link-e2e
----
+

Run java source integration tests
+
----
$ TEST_EXEC_NODES=1 make test-java-e2e
----
+

Run source integration tests
+
----
$ TEST_EXEC_NODES=1 make test-source-e2e
----
+

* For the login and logout command integration tests:
+
----
$ make test-odo-login-e2e
----
+

NOTE: `make test-odo-login-e2e` doesn't honour environment variable `TEST_EXEC_NODES`. So by default it runs login and logout command integration test suite on a single ginkgo test node sequentially to avoid race conditions in a parallel run.

* For the entire integration test suite:
+
----
$ make test-integration
----
+

NOTE: `make test-integration` doesn't honour enviornment variable `TEST_EXEC_NODES`. So by default it runs the entire integration test suite on a single ginkgo test node sequentially.

Similarly e2e (end to end) tests can be run in parallel and sequentially separately.

* To run the test in parallel (default: 2 ginkgo test node), on a test cluster:
+
Run core beta flow e2e test
+
----
$ make test-e2e-scenarios
----
+

* To run the test sequentially or on single ginkgo test node use enviornment variable `TEST_EXEC_NODES`:
+
Run core beta flow e2e test
+
----
$ TEST_EXEC_NODES=1 make test-e2e-scenarios
----

You can run a subset of tests with ginkgo by using focused specs mechanism https://onsi.github.io/ginkgo/#focused-specs

=== Race conditions

Test failures during the execution of the integration tests do occur. For example, the following error has been encountered multiple times:
----
Operation cannot be fulfilled on deploymentconfigs.apps.openshift.io "component-app": the object has been modified; please apply your changes to the latest version and try again
----

The reason this happens is because the _read DeploymentConfig_ or _update DC in memory_ or _call Update_ actions can potentially fail due to the DC being updated concurrently by some other component, usually by Kubernetes or OpenShift itself.

Thus it is recommended to avoid the read, update-in-memory, or push-update actions as much as possible. One remedy is to use the `Patch` operation, for more information see the link:https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/link:https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/[`Resource Operations`] section. Another remedy would be to retry the operation when the optimistic concurrency error is encountered.

=== Setting custom Init Container image for bootstrapping Supervisord
For quick deployment of components, odo uses the link:https://github.com/ochinchina/supervisord[Supervisord] process manager.
Supervisord is deployed via link:https://docs.openshift.com/container-platform/4.1/nodes/containers/nodes-containers-init.html[Init Container] image. 

`ODO_BOOTSTRAPPER_IMAGE` is an environmental variable which specifies the Init Container image used for Supervisord deployment.  You can modify the value of the variable to use a custom Init Container image.
The default Init Container image is `quay.io/openshiftdo/supervisord:0.6.0` 

. To set a custom Init Container image, run:
+
----
ODO_BOOTSTRAPPER_IMAGE=quay.io/myrepo/myimage:test
----

. To revert back to the default Init Container image, unset the variable:
+
----
unset ODO_BOOTSTRAPPER_IMAGE
----

== Dependency management

`odo` uses `glide` to manage dependencies. `glide` is not strictly required for building `odo` but it is required when managing dependencies under the `vendor/` directory.

If you want to make changes to dependencies please make sure that `glide` is installed and is in your `$PATH`.

=== Installing `glide`

. Download `glide`:
+
----
$ go get -u github.com/Masterminds/glide
----

. Check that `glide` is working
+
----
$ glide --version
----

=== Using glide to add a new dependency

==== Adding a new dependency

. Update the `glide.yaml` file. Add the new package or sub-packages to the `glide.yaml` file. You can add a whole new package as a dependency or just a few sub-packages.
. Run `glide update --strip-vendor` to get the new dependencies.
. Commit the updated `glide.yaml`, `glide.lock` and `vendor` files to git.

==== Updating dependencies

. Set new package version in `glide.yaml` file.
. Run `glide update --strip-vendor` to update dependencies

== Release guide

=== Releasing a new version

Making artifacts for a new release is automated. When a new git tag is created, the Travis-ci deploy job automatically builds binaries and uploads it to the GitHub release page.

To release a new version:

. Create a PR that:

* Updates the version in the following files:

** link:/pkg/odo/cli/version/version.go[`cmd/version.go`]
** link:/scripts/installer.sh[`scripts/installer.sh`]
+
There is a helper script link:../scripts/bump-version.sh[scripts/bump-version.sh] that changes version number in all the files listed above (except `odo.rb`).

* Updates the CLI reference documentation in the `docs/cli-reference.md` file:
+
----
$ make generate-cli-reference
----
. Merge the above PR.
. Once the PR is merged create and push the new git tag for the version.
+
----
$ git tag v0.0.1
$ git push upstream v0.0.1
----
*Or* create the new release using the GitHub site (this must be a proper release and not a draft).
+
NOTE: Do not upload any binaries for the release. When the new tag is created, Travis-CI starts a special deploy job. This job builds the binaries automatically (using `make prepare-release`) and then uploads it to the GitHub release page. When the job finishes you should see the binaries on the GitHub release page. The release is now marked as a draft.

. Update the descriptions and publish the release.
. Verify that packages have been uploaded to the `rpm` and `deb` repositories.
. Update the Homebrew package:
.. Check commit id for the released tag `git show-ref v0.0.1`
.. Create a PR to update `:tag` and `:revision` in the https://github.com/kadel/homebrew-odo/blob/master/Formula/odo.rb[`odo.rb`] file
in https://github.com/kadel/homebrew-odo[`kadel/homebrew-odo`].
. Confirm the binaries are available in the GitHub release page.
. Create a PR and update the file `build/VERSION` with the  latest version number.

== odo-bot

https://github.com/odo-bot[odo-bot] is the GitHub user that provides automation for certain tasks in `odo`.

It uses the `.travis.yml` script to upload binaries to the GitHub release page using the *deploy-github-release*
personal access token.

== Licenses

`odo` uses link:https://github.com/frapposelli/wwhrd[wwhrd] to  check license compatibility of vendor packages. The configuration for `wwhrd` is stored in link:https://github.com/openshift/odo/blob/master/.wwhrd.yml[`.wwhrd.yml`].

The `whitelist` section is for licenses that are always allowed. The `blacklist` section is for licenses that are never allowed and will always fail a build. Any licenses that are not explicitly mentioned come under the `exceptions` secion and need to be explicitly allowed by adding the import path to the exceptions.

More details about the license compatibility check tool can be found https://github.com/frapposelli/wwhrd[here]
